\documentclass[12pt,letter]{article}

%% \usepackage[fleqn]{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsfonts,amsthm,bm}
\usepackage{breqn}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{algorithm2e}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{subcaption}
%% \usepackage{datetime}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{mathrsfs}
\usepackage{fancyhdr}
\usepackage{fancyvrb}
\usepackage{parskip} %turns off paragraph indent
\usepackage{float}
\usepackage{empheq}
\usepackage{enumitem}

\pagestyle{fancy}

\usetikzlibrary{arrows}

\DeclareMathOperator*{\argmin}{argmin}
\newcommand*{\argminl}{\argmin\limits}

\DeclareMathOperator*{\argmax}{argmax}
\newcommand*{\argmaxl}{\argmax\limits}

\newcommand{\mathleft}{\@fleqntrue\@mathmargin0pt}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\ppartial}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\norm}[1]{\|#1\|}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\notimplies}{\;\not\!\!\!\implies}

\setcounter{MaxMatrixCols}{20}

\begin {document}

  % \begin{cases}
  %     0, & \text{if}\ a=1 \\
  %     1, & \text{otherwise}
  %   \end{cases}

\lhead{Convex Optimization - HW4}
\rhead{(Bill) Yuan Liu, 996954078, 2020/03/20}

\begin{enumerate}
  \item SDP Relaxation and Heuristics for Two-Way Partitioning Problem
  \begin{enumerate}
  \item Q 5.39 textbook\\
    \begin{align*}
      min\ x^T W x\\
      s.t.\ x_i^2 = 1, \forall i \in \{1,..,n\}\\
    \end{align*}
    \begin{enumerate}
    \item
    Show that the two-way partitioning problem can be cast as
    \begin{align*}
      min\ tr(WX)\\
      s.t.\ X \succeq 0, rank(X)=1\\
      X_{ii}=1, \forall i \in \{1,..,n\}
    \end{align*}

    \begin{align*}
      &x^T W x = tr(x^T W x)=tr(Wxx^T)\\
      &let\ X=xx^T\\
      &(\forall i) x_i^2 = 1 \iff x_i = \{-1,1\} \implies x^TIx = n\\
      &x^TIx = tr(xx^T)=n\\
      &(\forall i,j) X_{ij} = \{-1,1\}\\
      &((\exists i)X_{ii}=-1 \implies tr(X) < n)\\
      &thus, for\ tr(X)=n: (\forall i)X_{ii}=1\\
      \\
      &X=xx^T=x
      \begin{bmatrix}
        a_1 & a_2 & .. & a_n
      \end{bmatrix} =
                         \begin{bmatrix}
                           a_1 x & a_2 x & .. & a_n x
                         \end{bmatrix}, a_i \in \R, x \in \R^n\\
      &(\forall i)(\exists j) \beta_{ij} a_i x = a_j x \implies \beta_{ij} a_i x - a_j x = 0\\
      &let\ \gamma_{ij} = \beta_{ij} a_i - a_j\\
      &\gamma_{ij} x = 0\\
      &x\not=0 \implies ((\forall i)(\exists j) \gamma_{ij} = 0 \implies linear\ dependence\ between\ all\ column\ vectors\ of\ X)\\
      &thus,\ rank(X)=1\\
      \\
      &(\forall w) w^TXw = w^Txx^Tw = (x^Tw)^T x^Tw\\
      &(\forall i, w)(x^Tw)_i (x^Tw)_i \geq 0 \implies (\forall w)(x^Tw)^T (x^Tw) \geq 0 \iff X\ is\ SPD
    \end{align*}
    Combining all constraints and objective forms the desired result.
    \pagebreak
  \item
    SDP relaxation of two-way partitioning problem. Using the formulation in part (a), we can form the relaxation:
    \begin{align*}
      min\ tr(W X)\\
      s.t.\ X \succeq 0\\
      X_{ii} = 1, \forall i \in \{1,..,n\}
    \end{align*}
    This problem is an SDP, and therefore can be solved efficiently. Explain why its optimal value gives a lower bound on the optimal value of the two-way partitioning problem (5.113). What can you say if an optimal point $X^*$ for this SDP has rank one?
    \begin{align*}
      &L(X,Z,v) = tr(WX) - tr(XZ) + tr(diag(v)diag(X)-I)\\
      &L(X,Z,v) = -tr(diag(v)I) + tr(WX) - tr(XZ) + tr(diag(v)diag(X))\\
      &g(Z,V) =
        \begin{cases}
          -1^T v ,& W - Z + diag(v) \succeq 0\\
          -\infty ,& o/w
        \end{cases}\\
      &dual\ problem:\\
      &\max_{Z,v} -1^T v\\
      &s.t.\ W - Z + diag(v) \succeq 0\\
      &Z \succeq 0
    \end{align*}
    % Dual of original problem (5.114):
    % \begin{align*}
    %   &maximize\ -1^T v\\
    %   &s.t.\ W + diag(v) \succeq 0
    % \end{align*}
    % It is evident that solution to the dual of relaxed problem has a tightened inequality constraint due to $Z$.
    % \begin{align*}
    %   &W + diag(v) \succeq Z\\
    % \end{align*}
    % This leads to potentially bigger $v$ and hence potentially larger objective value to dual maximization problem (smaller objective value to the primal minimization problem). Thus, solution of relaxed problem provides a lower bound to the the original problem.\\
    
    % \pagebreak
    
    If an optimal point $X^*$ for the relaxed problem has rank one:\\
    $X^*$ has minimal possible rank and $X^*\not=0$, $X^*\succeq 0$.\\
    $X^*\succeq 0$, so primal feasible.\\
    Functions are all differentiable, KKT conditions apply at optimality where there exists a dual solution.\\
    Dual of relaxed problem is feasible: $W + diag(v) \succeq Z, Z\succeq 0$\\
    Using complementary slackness: $X^*\neq 0, -tr(X^*Z^*) = 0 \implies Z^* = 0$.\\
    
    Dual problem of relaxed problem at optimality:
    \begin{align*}
      &\max_{v,Z} -1^T v = [\max_{v}\ -1^T v]_{Z=Z^*}\\
      &s.t.\ W + diag(v) \succeq Z^*, Z^*=0 \implies \\
      &s.t.\ W + diag(v) \succeq 0
    \end{align*}
    This solution is equivalent to the solution of the dual of the original problem. Thus, if $rank(X^*)=1$ of the relaxed problem, $X^*$ obtains the same solution as the original problem where $x^*x^*^T=X^*$ as required.
    \pagebreak
  \item
    We now have two SDPs that give a lower bound on the optimal value of the two-way partitioning problem (5.113): the SDP relaxation (5.115) found in part (b), and the Lagrange dual of the two-way partitioning problem, given in (5.114). What is the relation between the two SDPs? What can you say about the lower bounds found by them? Hint: Relate the two SDPs via duality.
    \begin{align*}
      (5.115)\ &min\ tr(W X)\\
               &s.t.\ X \succeq 0\\
               &X_{ii} = 1, \forall i \in \{1,..,n\}
    \end{align*}
    \begin{align*}
      (5.114)\ &maximize\ -1^T v\\
               &s.t.\ W + diag(v) \succeq 0
    \end{align*}    
    % \pagebreak
    Taken from previous section, dual of relaxed problem:
    \begin{align*}
      &L(X,Z,v) = tr(WX) - tr(XZ) + tr(diag(v)diag(X)-I)\\
      &L(X,Z,v) = -tr(diag(v)I) + tr(WX) - tr(XZ) + tr(diag(v)diag(X))\\
      &g(Z,V) =
        \begin{cases}
          -1^T v ,& W - Z + diag(v) \succeq 0\\
          -\infty ,& o/w
        \end{cases}
    \end{align*}
    Dual problem:
    \begin{align*}
      &\max_{Z,v} -1^T v\\
      &s.t.\ W - Z + diag(v) \succeq 0\\
        &Z \succeq 0
      \end{align*}

      It is evident that solution to the dual of relaxed problem has a tightened generalized inequality constraint due to $Z$ compared to (5.114):
      \begin{align*}
        &W + diag(v) \succeq Z
      \end{align*}
      This leads to potentially bigger $v$ and hence potentially larger objective value of dual maximization problem (smaller objective value to the primal minimization problem). Thus, solution of relaxed problem provides a lower bound to the the original problem.\\
    \end{enumerate}
    
  \pagebreak
  
\item Q 11.23(b-d) textbook\\
  
  \begin{tabular}{|c|c|c|c|c|}\hline
          & SDP bound (11.66)& Optimum & b (11.67)& c \\ \hline
    small & -5.33445288482 &  & -12.30891878 & -5.33440509588\\ \hline
    medium & 42.2266162135 &  & 13.05483539 & -39.220002609\\ \hline
    large & -66.0855132055 & x & -2135.80923688 & -660.557123191\\ \hline
  \end{tabular}

    \begin{tabular}{|c|c|c|c|}\hline
      & d-a & d-b & d-c\\ \hline
      small & & &\\ \hline
      medium & & & \\ \hline
      large & & &\\ \hline
    \end{tabular}
\pagebreak
    \begin{itemize}
    \item b) heuristic partitioning
\begin{verbatim}
import cvxpy as cp
import numpy as np
from scipy.io import loadmat
from os.path import dirname, join as pjoin
import numpy.linalg as linalg

def solve(W):
    print("problem size:", W.shape[0])
    
    #dual of original:
    print("dual of original:")
    dim = W.shape[0]
    v = cp.Variable((dim,1))
    constraints = [W + cp.diag(v) >> 0]
    prob = cp.Problem(cp.Maximize( -cp.sum(v) ),
                      constraints)
    prob.solve()
    print("prob.status:", prob.status)
    
    lower_bound = 0
    if prob.status not in ["infeasible", "unbounded"]:
        # Otherwise, problem.value is inf or -inf, respectively.
        print("Optimal value: %s" % prob.value)
        lower_bound = prob.value

    lower_bound = -lower_bound
    print("lower_bound:", lower_bound)

    #dual of relaxed:
    print("dual of relaxed:")
    X = cp.Variable((dim,dim))
    constraints = [X >> 0, cp.diag(X) == np.ones((dim,))]
    prob = cp.Problem(cp.Minimize( cp.trace(cp.matmul(W,X)) ),
                      constraints)
    prob.solve()
    print("prob.status:", prob.status)
    
    if prob.status not in ["infeasible", "unbounded"]:
        # Otherwise, problem.value is inf or -inf, respectively.
        print("Optimal value: %s" % prob.value)

    ret = prob.variables()[0].value
    eigenValues, eigenVectors = linalg.eig(ret)

    idx = eigenValues.argsort()[::-1]
    eigenValues = eigenValues[idx]
    eigenVectors = eigenVectors[:,idx]
    x_approx = np.sign(eigenVectors[0])[:,np.newaxis]
    p_heuristic = (x_approx.T).dot(W).dot(x_approx)
    print("heuristic objective: ", p_heuristic)
    print("heuristic objective - lower_bound: ", p_heuristic - lower_bound)
    print("-----")
    
m = loadmat('../data/hw4data.mat')
w5 = np.array(m['W5'])
w10 = np.array(m['W10'])
w50 = np.array(m['W50'])

solve(w5)
solve(w10)
solve(w50)
\end{verbatim}
      \pagebreak
    \item c) randomized method
\begin{verbatim}
import cvxpy as cp
import numpy as np
from scipy.io import loadmat
from os.path import dirname, join as pjoin
import numpy.linalg as linalg
import math

def solve(W):
    print("problem size:", W.shape[0])
    
    #dual of original:
    print("dual of original:")
    dim = W.shape[0]
    v = cp.Variable((dim,1))
    constraints = [W + cp.diag(v) >> 0]
    prob = cp.Problem(cp.Maximize( -cp.sum(v) ),
                      constraints)
    prob.solve()

    print("prob.status:", prob.status)
    
    lower_bound = 0
    
    if prob.status not in ["infeasible", "unbounded"]:
        # Otherwise, problem.value is inf or -inf, respectively.
        print("Optimal value: %s" % prob.value)
        lower_bound = prob.value
        
    lower_bound = -lower_bound
    print("lower_bound: ", lower_bound)

    #dual of relaxed:
    print("dual of relaxed:")
    
    #restrict to PSD for randomized sampling
    #on proper covariance matrix later
    X = cp.Variable((dim,dim), PSD=True)
    
    constraints = [X >> 0, cp.diag(X) == np.ones((dim,))]
    prob = cp.Problem(cp.Minimize( cp.trace(cp.matmul(W,X)) ),
                      constraints)
    prob.solve(solver=cp.SCS, max_iters=4000, eps=1e-11, warm_start=True)

    print("prob.status:", prob.status)
    
    if prob.status not in ["infeasible", "unbounded"]:
        # Otherwise, problem.value is inf or -inf, respectively.
        print("Optimal value: %s" % prob.value)
    
    ret = prob.variables()[0].value
    eigenValues, eigenVectors = linalg.eig(ret)

    K = 100 #number of samples
    xs_approx = np.random.multivariate_normal(np.zeros((dim,)),
                                              ret, size=(K))
    xs_approx = np.sign(xs_approx)
    ps = xs_approx.dot(W).dot(xs_approx.T)
    p_best = np.amin(ps)
    print("best objective (randomized): ", p_best, "size: ", K)
    print("objective delta: best objective - lower_bound: ",
          p_best - lower_bound)
    print("-----")
    
m = loadmat('../data/hw4data.mat')
w5 = np.array(m['W5'])
w10 = np.array(m['W10'])
w50 = np.array(m['W50'])

solve(w5)
solve(w10)
solve(w50)
\end{verbatim}
      \pagebreak
    \item d) greedy heuristic refinement\\
    \end{itemize}
    \pagebreak    
  \end{enumerate}
  \item Interior Point Method
\end{enumerate}

\end {document}
